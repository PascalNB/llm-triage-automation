{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Automating the Cybersecurity Triage Process: A Comparative Study on the Performance of Large Language Models"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install required libraries, including OpenAI and Ollama"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install openai\n",
    "!pip install ollama\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install matplotlib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import libraries"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:11:23.346835Z",
     "start_time": "2024-06-17T17:11:20.110813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import median\n",
    "from abc import abstractmethod, ABC\n",
    "from typing import Any\n",
    "from openai import AzureOpenAI\n",
    "from ollama import Client"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Abstraction Class for Language Models and Prompts."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.244477Z",
     "start_time": "2024-06-17T16:51:51.238321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Prompt:\n",
    "\n",
    "    def __init__(self, system: str, user: str):\n",
    "        self.system = system\n",
    "        self.user = user\n",
    "\n",
    "\n",
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, model_id: str):\n",
    "        self.model_id = model_id\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate(self, prompt: Prompt) -> dict[str, str]:\n",
    "        pass\n",
    "\n",
    "\n",
    "class PromptGenerator:\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate(self, input_value: any) -> Prompt:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_id(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_field(self) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "class JsonPromptGenerator(PromptGenerator, ABC):\n",
    "\n",
    "    def __init__(self, data: dict[str, str]):\n",
    "        self.data = data\n",
    "\n",
    "    def get_field(self) -> str:\n",
    "        return self.data['field']\n",
    "\n",
    "    def get_id(self) -> str:\n",
    "        return self.data['id']\n",
    "\n",
    "\n",
    "def load_json(path: str) -> dict[str, Any]:\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Implement OpenAI Language Model."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.264345Z",
     "start_time": "2024-06-17T16:51:51.245495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OPENAI_KEY: str = os.getenv(\"OPENAI_KEY\")\n",
    "OPENAI_ENDPOINT: str = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT: str = os.getenv(\"OPENAI_DEPLOYMENT\")\n",
    "\n",
    "\n",
    "class OpenAILanguageModel(LanguageModel):\n",
    "    client = AzureOpenAI(azure_endpoint=OPENAI_ENDPOINT, api_key=OPENAI_KEY, api_version=\"2024-02-15-preview\")\n",
    "\n",
    "    def generate(self, prompt: Prompt) -> dict[str, str]:\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            response = OpenAILanguageModel.client.chat.completions.create(\n",
    "                model=self.model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt.system},\n",
    "                    {\"role\": \"user\", \"content\": prompt.user},\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            t1 = time.time()\n",
    "\n",
    "            return {'response': response.choices[0].message.content,\n",
    "                    'in_tokens': response.usage.prompt_tokens,\n",
    "                    'out_tokens': response.usage.completion_tokens,\n",
    "                    'time': t1 - t0}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Implement Ollama Language Model.\n",
    "\n",
    "**Note:** This requires Ollama to be running in the background on the address equal to `OLLAMA_HOST`.\n",
    "This is done by executing `ollama serve`."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.282006Z",
     "start_time": "2024-06-17T16:51:51.266356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OLLAMA_HOST = 'http://localhost:11434'\n",
    "\n",
    "\n",
    "class OllamaLanguageModel(LanguageModel):\n",
    "    client = Client(host=OLLAMA_HOST)\n",
    "\n",
    "    def generate(self, prompt: Prompt) -> dict[str, str]:\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            result = OllamaLanguageModel.client \\\n",
    "                .generate(model=self.model_id,\n",
    "                          system=prompt.system,\n",
    "                          prompt=prompt.user,\n",
    "                          format='json',\n",
    "                          stream=False)\n",
    "            # consider bug where repeated token limit is reached and output is aborted but not marked as done\n",
    "            if result['done']:\n",
    "                result['time'] = result['total_duration'] / 1e9\n",
    "            else:\n",
    "                result['time'] = time.time() - t0\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Create model clients.\n",
    "\n",
    "**Note:** This script assumes that the Ollama models have already been pulled."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.287422Z",
     "start_time": "2024-06-17T16:51:51.283014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models: dict[str, LanguageModel] = {\n",
    "    'llama3': OllamaLanguageModel('llama3:8b'),  # 8b\n",
    "    'phi3': OllamaLanguageModel('phi3:14b'),  # 14b\n",
    "    'phi3-mini': OllamaLanguageModel('phi3:3.8b'),  # 3.8b\n",
    "    'aya23': OllamaLanguageModel('aya:8b'),  # 8b\n",
    "    'mistral': OllamaLanguageModel('mistral:7b'),  # 7b\n",
    "    'codellama': OllamaLanguageModel('codellama:13b'),  # 7b\n",
    "    'gemma': OllamaLanguageModel('gemma:7b'),  # 7b\n",
    "    'gemma-mini': OllamaLanguageModel('gemma:2b'),  # 2b\n",
    "    'gpt4': OpenAILanguageModel(OPENAI_DEPLOYMENT),  # 1760b\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup evaluation framework"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T18:10:03.095024Z",
     "start_time": "2024-06-17T18:10:03.079143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_model_response(response: str, field: str) -> bool | None:\n",
    "    \"\"\"\n",
    "    Parse the JSON output of a language model and return True or False depending on the answer.\n",
    "    Incorrect JSON syntax will return False.\n",
    "    :param response: The JSON output of a language model.\n",
    "    :param field: The JSON key that contains the boolean value.\n",
    "    :return: True or False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response)[field]\n",
    "    except (TypeError, KeyError) as _:\n",
    "        return None\n",
    "\n",
    "\n",
    "def execute_all_on_model(model: LanguageModel, prompts: list[Prompt], delay: int = 0) -> list[dict[str, str]]:\n",
    "    result = []\n",
    "    first_run = True\n",
    "    for prompt in prompts:\n",
    "        if not first_run:\n",
    "            time.sleep(delay)\n",
    "            first_run = False\n",
    "        result.append(model.generate(prompt))  # execute prompt\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_prompts(prompt_generator: PromptGenerator, input_values: list[str]) -> list[Prompt]:\n",
    "    return [prompt_generator.generate(value) for value in input_values]\n",
    "\n",
    "\n",
    "def evaluate_model_outputs(predicted: list[bool], actual: list[bool]) -> dict[str, bool]:\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for _p, _a in zip(predicted, actual):\n",
    "        if _p and _a:\n",
    "            tp += 1\n",
    "        elif _p and not _a:\n",
    "            fp += 1\n",
    "        elif not _p and _a:\n",
    "            fn += 1\n",
    "        elif not _p and not _a:\n",
    "            tn += 1\n",
    "    return {'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn}\n",
    "\n",
    "\n",
    "def get_evaluation_statistics(evaluation: dict[str, int]) -> dict[str, float]:\n",
    "    tp, tn, fp, fn = evaluation['tp'], evaluation['tn'], evaluation['fp'], evaluation['fn']\n",
    "    accuracy = 0.0 if sum((tp, tn, fp, fn)) == 0 else (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = 0.0 if tp == 0 else tp / (tp + fp)\n",
    "    recall = 0.0 if tp == 0 else tp / (tp + fn)\n",
    "    f1 = 0.0 if tp == 0 else 2 * precision * recall / (precision + recall)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_model_responses(outputs: list[dict[str, str]]) -> list[str]:\n",
    "    return [output['response'] for output in outputs if 'response' in output]\n",
    "\n",
    "\n",
    "def run_evaluation(model: LanguageModel,\n",
    "                   prompts: list[Prompt],\n",
    "                   classifications: list[bool],\n",
    "                   field: str,\n",
    "                   delay: int = 0) -> dict[str, float]:\n",
    "    outputs: list[dict[str, str]] = execute_all_on_model(model, prompts, delay)\n",
    "    median_time = median(o['time'] for o in outputs if 'time' in o)\n",
    "    responses = get_model_responses(outputs)\n",
    "    parsed_raw = [parse_model_response(response, field) for response in responses]\n",
    "    errors = len([p for p in parsed_raw if p is None])\n",
    "    parsed = [p for p in parsed_raw if p is not None]\n",
    "    evaluation = evaluate_model_outputs(parsed, classifications)\n",
    "    statistics = get_evaluation_statistics(evaluation)\n",
    "    statistics['time'] = median_time\n",
    "    statistics['errors'] = errors\n",
    "    return statistics | evaluation\n",
    "\n",
    "\n",
    "def evaluate_all_models(language_models: dict[str, LanguageModel],\n",
    "                        prompt_generators: dict[str, PromptGenerator],\n",
    "                        dataset: tuple[list[str], list[bool]],\n",
    "                        delay: int = 0) -> dict[str, dict[str, dict[str, float]]]:\n",
    "    prompts_dict: dict[str, list[Prompt]] = {\n",
    "        key: generate_prompts(generator, dataset[0])\n",
    "        for key, generator in prompt_generators.items()\n",
    "    }\n",
    "\n",
    "    nested: dict[str, dict[str, dict[str, float]]] = dict()\n",
    "\n",
    "    for model_id, model in language_models.items():\n",
    "        print(model_id)\n",
    "        model_result = dict()\n",
    "        nested[model_id] = model_result\n",
    "        first_run = True\n",
    "        for prompt_id, prompts in prompts_dict.items():\n",
    "            print('\\t' + prompt_id)\n",
    "            if not first_run:  # wait between prompt runs\n",
    "                time.sleep(delay)\n",
    "                first_run = False\n",
    "            evaluation = run_evaluation(model, prompts, dataset[1], prompt_generators[prompt_id].get_field())\n",
    "            print('\\t\\t' + str(evaluation))\n",
    "            model_result[prompt_id] = evaluation\n",
    "\n",
    "    return nested\n",
    "\n",
    "\n",
    "def transform_evaluation(nested: dict[str, dict[str, dict[str, float]]]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame.from_dict(nested, orient='index').stack().to_frame()\n",
    "    return pd.DataFrame(df[0].values.tolist(), index=df.index)\n"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Detect Email Announcements\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:36:27.794006Z",
     "start_time": "2024-06-17T17:36:27.788728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DetectAnnouncementPrompt(JsonPromptGenerator):\n",
    "\n",
    "    def generate(self, email: str) -> Prompt:\n",
    "        return Prompt(self.data['system'], self.data['user'] + '\\n' + email)\n",
    "\n",
    "\n",
    "detect_email_announcement_prompts: dict[str, PromptGenerator] = {\n",
    "    key: DetectAnnouncementPrompt(value)\n",
    "    for key, value in load_json('data/detect_announcement_prompts.json').items()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get announcement email dataset."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.734969Z",
     "start_time": "2024-06-17T16:51:51.310696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "announcement_emails = pd.read_excel('data/announcement_emails.xlsx') \\\n",
    "    .rename(columns={'cleaned_email_body': 'email'})[['email']]\n",
    "announcement_emails['is_announcement'] = True\n",
    "announcement_emails"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                email  is_announcement\n",
       "0   name13 will be working on AZWEU-OLSTB01 today....             True\n",
       "1   We will add the user name15 as a owner to the ...             True\n",
       "2   name16 will use his admin account (Ka6053adm) ...             True\n",
       "3   We did some testing on the SRV602 with discove...             True\n",
       "4   name1 applied the scheduled task to the SVR-ND...             True\n",
       "5   name2 just created an external mail forwarding...             True\n",
       "6   name3 be loggin in on the VM-DCS-01 with my Ex...             True\n",
       "7   customer3 announced that the user 'jedox-power...             True\n",
       "8   name4 will add the user Jayy.Watson01 to the b...             True\n",
       "9   customer5 will add the user “sea_line” to the ...             True\n",
       "10  name5 will create the following administrative...             True\n",
       "11  Hi,\\n\\nFYI iam changing some membership in hig...             True\n",
       "12  I will be scanning this issue on our AD/ ADCS ...             True\n",
       "13  We will create two groups:\\nLG_ADMIN-NLD-CIT-S...             True\n",
       "14  I want to inform you about a planned addition ...             True\n",
       "15  Host VMIVM1 is being upgraded from Windows Ser...             True\n",
       "16  customer7 will install WinSCP on SVR-NDK-TRAC,...             True\n",
       "17  Please be advised, colleague name12 will use t...             True\n",
       "18  Last time customer9 migrated the files from ou...             True\n",
       "19  custome10 is going to add account ‘svc_bck_dc@...             True"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>is_announcement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name13 will be working on AZWEU-OLSTB01 today....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We will add the user name15 as a owner to the ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name16 will use his admin account (Ka6053adm) ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We did some testing on the SRV602 with discove...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name1 applied the scheduled task to the SVR-ND...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>name2 just created an external mail forwarding...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>name3 be loggin in on the VM-DCS-01 with my Ex...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>customer3 announced that the user 'jedox-power...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>name4 will add the user Jayy.Watson01 to the b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>customer5 will add the user “sea_line” to the ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name5 will create the following administrative...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hi,\\n\\nFYI iam changing some membership in hig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I will be scanning this issue on our AD/ ADCS ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>We will create two groups:\\nLG_ADMIN-NLD-CIT-S...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I want to inform you about a planned addition ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Host VMIVM1 is being upgraded from Windows Ser...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>customer7 will install WinSCP on SVR-NDK-TRAC,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Please be advised, colleague name12 will use t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Last time customer9 migrated the files from ou...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>custome10 is going to add account ‘svc_bck_dc@...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get normal emails from Enron dataset."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.766668Z",
     "start_time": "2024-06-17T16:51:51.735982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normal_emails = pd.read_csv('data/enron.csv', nrows=500) \\\n",
    "    .rename(columns={'Message': 'email'})[['email']]\n",
    "normal_emails_sizes = normal_emails['email'].map(len)  # get email sizes\n",
    "normal_emails = normal_emails[(normal_emails_sizes > 100) & (normal_emails_sizes < 500)] \\\n",
    "    .sample(20)  # filter by email size and select 20\n",
    "normal_emails['is_announcement'] = False\n",
    "normal_emails"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 email  is_announcement\n",
       "261  Julie,\\n\\n The numbers for January are below:\\...            False\n",
       "289  Jim,\\n\\nIs there going to be a conference call...            False\n",
       "294  Alan, \\n\\nYou should have received updated num...            False\n",
       "14   Dave, \\n\\n Here are the names of the west desk...            False\n",
       "307  I just spoke to the insurance company.  They a...            False\n",
       "165  Lucy,\\n\\n I want to speak to Wade myself.  He ...            False\n",
       "355  Larry,\\n\\nJacques has sent a document to Claud...            False\n",
       "491  George,\\n\\nWe should hear from the bank in Hou...            False\n",
       "473  ---------------------- Forwarded by Phillip K ...            False\n",
       "313  Andrea,\\n\\nAfter reviewing Bryan Hull's resume...            False\n",
       "64   Ina,\\n\\n Can you pull Tori K.'s and Martin Cui...            False\n",
       "120  can you build something to look at historical ...            False\n",
       "209  ---------------------- Forwarded by Phillip K ...            False\n",
       "114  ---------------------- Forwarded by Phillip K ...            False\n",
       "70   Cooper,\\n \\n Can you give access to the new we...            False\n",
       "126  Wade,\\n\\n I understood your number one priorit...            False\n",
       "39   Jim,\\n\\nIs there going to be a conference call...            False\n",
       "155  Lucy,\\n\\nI got your email.  I didn't have time...            False\n",
       "48   ---------------------- Forwarded by Phillip K ...            False\n",
       "102  Cooper,\\n\\nThis is the website I use:\\n\\nhttp:...            False"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>is_announcement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Julie,\\n\\n The numbers for January are below:\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Jim,\\n\\nIs there going to be a conference call...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Alan, \\n\\nYou should have received updated num...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dave, \\n\\n Here are the names of the west desk...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>I just spoke to the insurance company.  They a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Lucy,\\n\\n I want to speak to Wade myself.  He ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Larry,\\n\\nJacques has sent a document to Claud...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>George,\\n\\nWe should hear from the bank in Hou...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Andrea,\\n\\nAfter reviewing Bryan Hull's resume...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ina,\\n\\n Can you pull Tori K.'s and Martin Cui...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>can you build something to look at historical ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Cooper,\\n \\n Can you give access to the new we...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Wade,\\n\\n I understood your number one priorit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Jim,\\n\\nIs there going to be a conference call...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Lucy,\\n\\nI got your email.  I didn't have time...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Cooper,\\n\\nThis is the website I use:\\n\\nhttp:...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Concatenate the announcement and non-announcement datasets."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:51:51.776157Z",
     "start_time": "2024-06-17T16:51:51.767675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emails = pd.concat([announcement_emails, normal_emails]).sample(frac=1).reset_index(drop=True)\n",
    "emails"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                email  is_announcement\n",
       "0   I will be scanning this issue on our AD/ ADCS ...             True\n",
       "1   We will create two groups:\\nLG_ADMIN-NLD-CIT-S...             True\n",
       "2   Jim,\\n\\nIs there going to be a conference call...            False\n",
       "3   ---------------------- Forwarded by Phillip K ...            False\n",
       "4   can you build something to look at historical ...            False\n",
       "5   Larry,\\n\\nJacques has sent a document to Claud...            False\n",
       "6   Cooper,\\n\\nThis is the website I use:\\n\\nhttp:...            False\n",
       "7   Hi,\\n\\nFYI iam changing some membership in hig...             True\n",
       "8   Lucy,\\n\\nI got your email.  I didn't have time...            False\n",
       "9   custome10 is going to add account ‘svc_bck_dc@...             True\n",
       "10  name3 be loggin in on the VM-DCS-01 with my Ex...             True\n",
       "11  Lucy,\\n\\n I want to speak to Wade myself.  He ...            False\n",
       "12  customer3 announced that the user 'jedox-power...             True\n",
       "13  Last time customer9 migrated the files from ou...             True\n",
       "14  George,\\n\\nWe should hear from the bank in Hou...            False\n",
       "15  ---------------------- Forwarded by Phillip K ...            False\n",
       "16  name16 will use his admin account (Ka6053adm) ...             True\n",
       "17  We did some testing on the SRV602 with discove...             True\n",
       "18  customer7 will install WinSCP on SVR-NDK-TRAC,...             True\n",
       "19  Host VMIVM1 is being upgraded from Windows Ser...             True\n",
       "20  name1 applied the scheduled task to the SVR-ND...             True\n",
       "21  name4 will add the user Jayy.Watson01 to the b...             True\n",
       "22  Julie,\\n\\n The numbers for January are below:\\...            False\n",
       "23  I just spoke to the insurance company.  They a...            False\n",
       "24  name2 just created an external mail forwarding...             True\n",
       "25  Ina,\\n\\n Can you pull Tori K.'s and Martin Cui...            False\n",
       "26  ---------------------- Forwarded by Phillip K ...            False\n",
       "27  Alan, \\n\\nYou should have received updated num...            False\n",
       "28  We will add the user name15 as a owner to the ...             True\n",
       "29  Andrea,\\n\\nAfter reviewing Bryan Hull's resume...            False\n",
       "30  Cooper,\\n \\n Can you give access to the new we...            False\n",
       "31  name5 will create the following administrative...             True\n",
       "32  customer5 will add the user “sea_line” to the ...             True\n",
       "33  ---------------------- Forwarded by Phillip K ...            False\n",
       "34  Jim,\\n\\nIs there going to be a conference call...            False\n",
       "35  Dave, \\n\\n Here are the names of the west desk...            False\n",
       "36  name13 will be working on AZWEU-OLSTB01 today....             True\n",
       "37  I want to inform you about a planned addition ...             True\n",
       "38  Please be advised, colleague name12 will use t...             True\n",
       "39  Wade,\\n\\n I understood your number one priorit...            False"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>is_announcement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I will be scanning this issue on our AD/ ADCS ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We will create two groups:\\nLG_ADMIN-NLD-CIT-S...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jim,\\n\\nIs there going to be a conference call...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you build something to look at historical ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Larry,\\n\\nJacques has sent a document to Claud...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cooper,\\n\\nThis is the website I use:\\n\\nhttp:...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hi,\\n\\nFYI iam changing some membership in hig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lucy,\\n\\nI got your email.  I didn't have time...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>custome10 is going to add account ‘svc_bck_dc@...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name3 be loggin in on the VM-DCS-01 with my Ex...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lucy,\\n\\n I want to speak to Wade myself.  He ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>customer3 announced that the user 'jedox-power...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Last time customer9 migrated the files from ou...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>George,\\n\\nWe should hear from the bank in Hou...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>name16 will use his admin account (Ka6053adm) ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>We did some testing on the SRV602 with discove...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>customer7 will install WinSCP on SVR-NDK-TRAC,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Host VMIVM1 is being upgraded from Windows Ser...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>name1 applied the scheduled task to the SVR-ND...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>name4 will add the user Jayy.Watson01 to the b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Julie,\\n\\n The numbers for January are below:\\...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I just spoke to the insurance company.  They a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>name2 just created an external mail forwarding...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ina,\\n\\n Can you pull Tori K.'s and Martin Cui...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Alan, \\n\\nYou should have received updated num...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>We will add the user name15 as a owner to the ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Andrea,\\n\\nAfter reviewing Bryan Hull's resume...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cooper,\\n \\n Can you give access to the new we...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>name5 will create the following administrative...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>customer5 will add the user “sea_line” to the ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>---------------------- Forwarded by Phillip K ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Jim,\\n\\nIs there going to be a conference call...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Dave, \\n\\n Here are the names of the west desk...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>name13 will be working on AZWEU-OLSTB01 today....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I want to inform you about a planned addition ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Please be advised, colleague name12 will use t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Wade,\\n\\n I understood your number one priorit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split into dataset for prediction and actual classification."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T18:15:06.161465Z",
     "start_time": "2024-06-17T18:15:06.161465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "email_bodies: list[str] = [*emails['email'].values][0:1]\n",
    "is_actual_announcement: list[bool] = [*emails['is_announcement'].values][0:1]\n",
    "detect_announcement_dataset = (email_bodies, is_actual_announcement)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run all prompts on all models."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:53:43.771186Z",
     "start_time": "2024-06-17T17:36:42.634806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "announcement_detection_evaluation_dict = evaluate_all_models(\n",
    "    {i: models[i] for i in models if i != 'gpt4'},\n",
    "    detect_email_announcement_prompts,\n",
    "    detect_announcement_dataset\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.95, 'precision': 0.95, 'recall': 0.95, 'f1': 0.9500000000000001, 'time': 0.6334123, 'errors': 0, 'tp': 19, 'tn': 19, 'fp': 1, 'fn': 1}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.825, 'precision': 0.8095238095238095, 'recall': 0.85, 'f1': 0.8292682926829269, 'time': 0.6472122499999999, 'errors': 0, 'tp': 17, 'tn': 16, 'fp': 4, 'fn': 3}\n",
      "phi3\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.6666666666666666, 'precision': 0.6666666666666666, 'recall': 0.5882352941176471, 'f1': 0.625, 'time': 2.9068880999999998, 'errors': 4, 'tp': 10, 'tn': 14, 'fp': 5, 'fn': 7}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.375, 'precision': 0.2857142857142857, 'recall': 0.2857142857142857, 'f1': 0.2857142857142857, 'time': 2.889226, 'errors': 24, 'tp': 2, 'tn': 4, 'fp': 5, 'fn': 5}\n",
      "phi3-mini\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.95, 'precision': 1.0, 'recall': 0.9, 'f1': 0.9473684210526316, 'time': 0.8543130159378052, 'errors': 0, 'tp': 18, 'tn': 20, 'fp': 0, 'fn': 2}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.675, 'precision': 0.8181818181818182, 'recall': 0.45, 'f1': 0.5806451612903226, 'time': 0.8622888326644897, 'errors': 0, 'tp': 9, 'tn': 18, 'fp': 2, 'fn': 11}\n",
      "aya23\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.675, 'precision': 0.6206896551724138, 'recall': 0.9, 'f1': 0.7346938775510204, 'time': 1.4076557, 'errors': 0, 'tp': 18, 'tn': 9, 'fp': 11, 'fn': 2}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.6, 'precision': 0.6111111111111112, 'recall': 0.55, 'f1': 0.5789473684210527, 'time': 1.3951970999999999, 'errors': 0, 'tp': 11, 'tn': 13, 'fp': 7, 'fn': 9}\n",
      "mistral\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.85, 'precision': 0.85, 'recall': 0.85, 'f1': 0.85, 'time': 0.4126993, 'errors': 0, 'tp': 17, 'tn': 17, 'fp': 3, 'fn': 3}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.75, 'precision': 0.8571428571428571, 'recall': 0.6, 'f1': 0.7058823529411764, 'time': 0.40150885000000003, 'errors': 0, 'tp': 12, 'tn': 18, 'fp': 2, 'fn': 8}\n",
      "codellama\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.75, 'precision': 0.75, 'recall': 0.75, 'f1': 0.75, 'time': 3.42852025, 'errors': 0, 'tp': 15, 'tn': 15, 'fp': 5, 'fn': 5}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.625, 'precision': 0.631578947368421, 'recall': 0.6, 'f1': 0.6153846153846154, 'time': 3.25185145, 'errors': 0, 'tp': 12, 'tn': 13, 'fp': 7, 'fn': 8}\n",
      "gemma\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.725, 'precision': 0.9090909090909091, 'recall': 0.5, 'f1': 0.6451612903225806, 'time': 1.6420027, 'errors': 0, 'tp': 10, 'tn': 19, 'fp': 1, 'fn': 10}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.8, 'precision': 0.8333333333333334, 'recall': 0.75, 'f1': 0.7894736842105262, 'time': 1.64621405, 'errors': 0, 'tp': 15, 'tn': 17, 'fp': 3, 'fn': 5}\n",
      "gemma-mini\n",
      "\tlong\n",
      "\t\t{'accuracy': 0.55, 'precision': 1.0, 'recall': 0.1, 'f1': 0.18181818181818182, 'time': 0.1898805, 'errors': 0, 'tp': 2, 'tn': 20, 'fp': 0, 'fn': 18}\n",
      "\tshort\n",
      "\t\t{'accuracy': 0.5, 'precision': 0.5, 'recall': 0.8, 'f1': 0.6153846153846154, 'time': 0.19079415, 'errors': 0, 'tp': 16, 'tn': 4, 'fp': 16, 'fn': 4}\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T18:17:38.135729Z",
     "start_time": "2024-06-17T18:15:37.125390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "announcement_detection_evaluation_dict_gpt4 = evaluate_all_models(\n",
    "    {'gpt4': models['gpt4']},\n",
    "    detect_email_announcement_prompts,\n",
    "    detect_announcement_dataset,\n",
    "    7  # seconds delay between prompts\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4\n",
      "\tlong\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHTTPStatusError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:999\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    998\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 999\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1000\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m err:  \u001B[38;5;66;03m# thrown on 4xx and 5xx status code\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\httpx\\_models.py:761\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    760\u001B[0m message \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m, error_type\u001B[38;5;241m=\u001B[39merror_type)\n\u001B[1;32m--> 761\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m HTTPStatusError(message, request\u001B[38;5;241m=\u001B[39mrequest, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[1;31mHTTPStatusError\u001B[0m: Client error '429 Too Many Requests' for url 'https://beau-research.openai.azure.com//openai/deployments/beau-research/chat/completions?api-version=2024-02-15-preview'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mHTTPStatusError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:999\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    998\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 999\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1000\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m err:  \u001B[38;5;66;03m# thrown on 4xx and 5xx status code\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\httpx\\_models.py:761\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    760\u001B[0m message \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m, error_type\u001B[38;5;241m=\u001B[39merror_type)\n\u001B[1;32m--> 761\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m HTTPStatusError(message, request\u001B[38;5;241m=\u001B[39mrequest, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[1;31mHTTPStatusError\u001B[0m: Client error '429 Too Many Requests' for url 'https://beau-research.openai.azure.com//openai/deployments/beau-research/chat/completions?api-version=2024-02-15-preview'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[84], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m announcement_detection_evaluation_dict_gpt4 \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_all_models\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgpt4\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgpt4\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdetect_email_announcement_prompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdetect_announcement_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# seconds delay between prompts\u001B[39;49;00m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[81], line 101\u001B[0m, in \u001B[0;36mevaluate_all_models\u001B[1;34m(language_models, prompt_generators, dataset, delay)\u001B[0m\n\u001B[0;32m     99\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(delay)\n\u001B[0;32m    100\u001B[0m     first_run \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 101\u001B[0m evaluation \u001B[38;5;241m=\u001B[39m \u001B[43mrun_evaluation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_generators\u001B[49m\u001B[43m[\u001B[49m\u001B[43mprompt_id\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_field\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(evaluation))\n\u001B[0;32m    103\u001B[0m model_result[prompt_id] \u001B[38;5;241m=\u001B[39m evaluation\n",
      "Cell \u001B[1;32mIn[81], line 67\u001B[0m, in \u001B[0;36mrun_evaluation\u001B[1;34m(model, prompts, classifications, field, delay)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_evaluation\u001B[39m(model: LanguageModel,\n\u001B[0;32m     63\u001B[0m                    prompts: \u001B[38;5;28mlist\u001B[39m[Prompt],\n\u001B[0;32m     64\u001B[0m                    classifications: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mbool\u001B[39m],\n\u001B[0;32m     65\u001B[0m                    field: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m     66\u001B[0m                    delay: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]:\n\u001B[1;32m---> 67\u001B[0m     outputs: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[43mexecute_all_on_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m     median_time \u001B[38;5;241m=\u001B[39m median(o[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m o \u001B[38;5;129;01min\u001B[39;00m outputs \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m o)\n\u001B[0;32m     69\u001B[0m     responses \u001B[38;5;241m=\u001B[39m get_model_responses(outputs)\n",
      "Cell \u001B[1;32mIn[81], line 22\u001B[0m, in \u001B[0;36mexecute_all_on_model\u001B[1;34m(model, prompts, delay)\u001B[0m\n\u001B[0;32m     20\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(delay)\n\u001B[0;32m     21\u001B[0m         first_run \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m     result\u001B[38;5;241m.\u001B[39mappend(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m)  \u001B[38;5;66;03m# execute prompt\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "Cell \u001B[1;32mIn[4], line 12\u001B[0m, in \u001B[0;36mOpenAILanguageModel.generate\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     11\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 12\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mOpenAILanguageModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msystem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msystem\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjson_object\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m}\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     t1 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m'\u001B[39m: response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent,\n\u001B[0;32m     23\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min_tokens\u001B[39m\u001B[38;5;124m'\u001B[39m: response\u001B[38;5;241m.\u001B[39musage\u001B[38;5;241m.\u001B[39mprompt_tokens,\n\u001B[0;32m     24\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout_tokens\u001B[39m\u001B[38;5;124m'\u001B[39m: response\u001B[38;5;241m.\u001B[39musage\u001B[38;5;241m.\u001B[39mcompletion_tokens,\n\u001B[0;32m     25\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m: t1 \u001B[38;5;241m-\u001B[39m t0}\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 277\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:606\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    574\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    604\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    605\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m--> 606\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    612\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    614\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    615\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    616\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    620\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    625\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    638\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    639\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    641\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:1240\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1227\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1228\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1235\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1236\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1237\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1238\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1239\u001B[0m     )\n\u001B[1;32m-> 1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:921\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    912\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    913\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    914\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    919\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    920\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:1005\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[0;32m   1004\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m-> 1005\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1007\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1008\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1009\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1010\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1011\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1012\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:1053\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[1;32m-> 1053\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1054\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1055\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1056\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1057\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1058\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1059\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:1005\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[0;32m   1004\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m-> 1005\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1006\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1007\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1008\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1009\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1010\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1011\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1012\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[1;32m~\\Documents\\School\\TCS\\Year 3\\Research Project\\llm-triage-automation\\env\\Lib\\site-packages\\openai\\_base_client.py:1051\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1047\u001B[0m log\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrying request to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m in \u001B[39m\u001B[38;5;132;01m%f\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m\"\u001B[39m, options\u001B[38;5;241m.\u001B[39murl, timeout)\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m-> 1051\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m   1053\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[0;32m   1054\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   1055\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1058\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m   1059\u001B[0m )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transform output into dataframe."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:54:03.495595Z",
     "start_time": "2024-06-17T17:54:03.462622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "announcement_detection_evaluation = transform_evaluation(\n",
    "    announcement_detection_evaluation_dict | announcement_detection_evaluation_dict_gpt4\n",
    ")\n",
    "announcement_detection_evaluation.index = announcement_detection_evaluation.index.rename(['model', 'prompt'])"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T18:01:14.284052Z",
     "start_time": "2024-06-17T18:01:14.138735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "announcement_detection_f1 = announcement_detection_evaluation['f1']\n",
    "announcement_detection_f1.unstack() \\\n",
    "    .sort_values(by=next(iter(detect_email_announcement_prompts.keys())), ascending=False) \\\n",
    "    .plot(kind='barh')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='model'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
