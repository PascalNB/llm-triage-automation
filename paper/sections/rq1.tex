\section{Optimizing Triage Using LLMs}
\label{sec:rq1}

This section intends to answer RQ1: \textit{How can LLMs be integrated into the existing incident response workflow to
streamline the triage process?}
Firstly, a rundown of the triage process is given by providing examples of the steps taken when identifying the priority
of an alarm.
Secondly, existing and proposed solutions of optimizing triage are summarized.
Then, a general use of LLMs is given using a brief overview of the recent advances made in NLP\@, after which examples
of LLMs performing relevant tasks are provided.
Lastly, using these findings, \dots (answer RQ1) % TODO

\subsection{Steps of Triage}
\label{subsec:rq1-steps-of-triage}

(TODO: What is triage in detail?) % TODO

\subsection{Existing Triage Automations/Optimizations}
\label{subsec:rq1-existing-optimizations}

One goal of triage is to correlate alarms, which means identifying if the alarms are related to eventually determine in
what part of the kill chain it belongs.
\citet{ficke2022reconstructing} optimizes this step by using alert trees.
These trees are data structures used to organize and visualize generated alerts.
The alerts are structured hierarchically, showing the relationships between alerts and the sequence of events.
The proposed solution also removes redundancies in the graphs, preventing the graphs to reach sizes of thousands of
nodes.
Based on academic datasets, the result is a system that quickly reconstructs paths that give insight into multistep
threats in a network, which is an otherwise time-consuming task for human analysts.
(TODO: How are alert paths detected) % TODO

\citet{serketzis2019improving} propose a model that integrates Cyber Threat Intelligence (CTI) into the process.
CTI involves collecting and analyzing information about potential and existing threats.
The model aims to enhance Digital Forensic Readiness (DFR), which is the preparation of digital forensics through
collection and storage of data, to create relevant readily available information.
Three independent but interrelated modules form the basis of the model:
\begin{enumerate}
    \item \textbf{IoC Collection Module.}
    Indicators of Compromise (IoC) consist of indicators of malicious activity observed in networks or systems.
    The module aggregates IoC from many internal and external sources of CTI to increase the collective knowledge.
    Data is evaluated and correlated to further increase its value, after which it is kept in a database.
    \item \textbf{Audit Log Processing Module.}
    This module aims to gather, validate and process audit log data generated by different parts within the
    organization.
    The data is stored in a dedicated database, which handles retrieval requests from the last module.
    \item \textbf{Threat Identification Module.}
    This module cross-matches the contents produced by the other modules and identifies threats.
    The evidence is stored in Intelligence Evidence Storage Systems (IESSs), which act as an entry point for analysts
    looking to preview potentially adverse incidents.
    Besides identifying suspicious activity, the module provides potential instigating factors.
\end{enumerate}
The resulting model is shown to have a high accuracy of 90.73\%.

(TODO: limitations of existing solutions (don't consider steps involving human language)) % TODO

\subsection{General Usage of LLMs}
\label{subsec:rq1-use-of-llms}

LLMs make use of Natural Language Understanding (NLU) and Natural Language Generation (NLG).
NLU aims to comprehend meaning and intent in natural language, while NLG focuses on generating original human-like
texts.
To achieve NLU and NLG, language models make use of so-called encoders and decoders.
The purpose of encoders is to turn input texts into fixed-size vectors that act as abstract representations.
Language models then use decoders to turn such representations into a generated target output.
This approach works well on tasks that map input sequences to output sequences (sec2sec), such as language
translation\ \citep{sutskever2014sequence, cho2014learning}.

In 2014,\ \citet{bahdanau2014neural} introduced the concept of attention which rids the encoders of creating
fixed-length vectors, allowing language models to focus on the most relevant parts of texts and enabling operations on
much longer input sequences.
Based on this,\ \citet{vaswani2017attention} developed the transformer architecture in 2017, setting the precedent for
modern LLMs.
Transformers are superior in quality, more parallelizable, and take less time to train.

Early well-known examples of such transformer-based models are BERT
(Bidirectional Encoder Representations from Transformers)\ \citep{devlin2018bert}, and
GPT (Generative Pre-trained Transformer)\ \citep{radford2018improving}.
\begin{itemize}
    \item BERT was specifically designed as a pre-trained model to be easily fine-tuned for a wide range of tasks such
    as answering questions and natural language inference, without the need of task-specific architecture.
    In the cybersecurity domain, BERT models have been fine-tuned to detect malicious
    software\ \citep{rahali2021malbert} and phishing emails\ \citep{lee2020catbert}.
    \item GPT is pre-trained on a large amount of unlabeled data and designed to generate coherent context-specific
    text.
    Like BERT, it requires fine-tuning to adapt the model to specific tasks.
\end{itemize}

(TODO: disadvantages fine-tuned models vs general models) % TODO

(TODO: general uses of LLMs) % TODO

\subsection{Using LLMs to Optimize Triage}
\label{subsec:rq1-llms-in-context}

Answering RQ1.