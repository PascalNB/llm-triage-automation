\section{Optimizing Triage Using LLMs}
\label{sec:rq1}

This section intends to answer RQ1:
\textit{How can LLMs be integrated into the existing incident response workflow to streamline the triage process?}
Firstly, a rundown of the triage process is given by providing examples of the steps taken when identifying the priority
of an alarm.
Secondly, existing and proposed solutions of optimizing triage are summarized.
Then, a general use of LLMs is given using a brief overview of the recent advances made in NLP, after which examples
of LLMs performing relevant tasks are provided.
Lastly, using these findings, possible automations in the triage process are identified.

\subsection{Steps of Triage}
\label{subsec:rq1-steps-of-triage}

The goal of triage is to follow a structured process to quickly assess and prioritize security alarms.
Although the steps of triage are not set in stone and depend on the type of alarm, there are a number of basic tasks
that can be followed.
Based on consultations with security analysts, the following tasks can be identified:
\begin{enumerate}
    \item \textbf{Understanding the alarm:} The security analyst intends to understand the nature of the alarm.
    This includes the origin of the alarm (e.g.,\ in the cloud or on-premise) and what time it was created.
    Besides this, the analyst reviews any prior communications that suggest the possibility of alarm creation, and
    assesses its relevance to the alarm in question.

    \item \textbf{Analyzing the context:} The analyst looks through the given alarm data and identifies the affected
    entities and to what extent they are affected.
    This includes users, data, systems and operations.

    \item \textbf{Correlating the alarm:}
    Based on the alarm context, the analyst searches whether the alarm has been previously encountered or if related
    alarms have occurred, either within the affected network or a different one.

    \item \textbf{Identifying the position in the kill chain:}
    To assess potential consequences, the position of the alarm within the kill chain is determined.
    A kill chain describes the stages of a cyberattack, from initial reconnaissance to the final goal.
    This is done by referencing the MITRE ATT\&CK\ \citep{strom2018mitre} or Cyber Kill Chain\ \citep{lockheed2011ckc}
    frameworks.
    This also depends on other potentially correlated alarms.

    \item \textbf{Prioritizing the alarm:}
    The analyst concludes how severe the alarm is and assigns a priority of high, medium, low or no threat.
    The priority classification determines how quickly an alarm requires further analysis and response actions.
\end{enumerate}

The overall process should ideally not take longer than 30 minutes, because high-priority alarms need to be handled as
urgently as possible.
To meet this time constraint, it is essential to integrate tools and processes to allow analysts to perform triage
efficiently.

\subsection{Existing Triage Automations/Optimizations}
\label{subsec:rq1-existing-optimizations}

One goal of triage is to correlate alarms, which entails identifying if the alarms are related to determine their
placement within the kill chain.
\citet{ficke2022reconstructing} optimizes this step by using alert trees.
These trees are data structures used to organize and visualize generated alerts.
The alerts are structured hierarchically, showing the relationships between alerts and the sequence of events.
The proposed solution also eliminates redundancies in the graphs, thereby preventing the graphs from reaching sizes
consisting of thousands of nodes.
Based on academic datasets, the result is a system that quickly reconstructs paths that give insight into multistep
threats in a network, which is an otherwise time-consuming task for human analysts.

Additionally,\ \citet{serketzis2019improving} propose a model that integrates Cyber Threat Intelligence (CTI) into the
process.
CTI involves collecting and analyzing information about potential and existing threats.
The model aims to enhance Digital Forensic Readiness (DFR), which is the preparation of digital forensics through
collection and storage of data, to create relevant readily available information.
Three independent but interrelated modules form the basis of the model:
\begin{itemize}
    \item \textbf{IoC Collection Module:}
    Indicators of Compromise (IoC) consist of indicators of malicious activity observed in networks or systems.
    The module aggregates IoC from many internal and external sources of CTI to increase the collective knowledge.
    Data is evaluated and correlated to further increase its value, after which it is kept in a database.

    \item \textbf{Audit Log Processing Module:}
    This module aims to gather, validate and process audit log data generated by different parts within the
    organization.
    The data is stored in a dedicated database, which handles retrieval requests from the third module.

    \item \textbf{Threat Identification Module:}
    This module cross-matches the contents produced by the other modules and identifies threats.
    The evidence is stored in Intelligence Evidence Storage Systems (IESSs), which act as an entry point for analysts
    looking to preview potentially adverse incidents.
    Besides identifying suspicious activity, the module provides potential instigating factors.
\end{itemize}
The resulting model is shown to have a high accuracy of 90.73\% when testing network data for malicious activity.

Besides that,\ \citet{zhong2018learning} approached the automation of triage by tracing the operations of professional
security analysts.
As junior analysts are typically responsible for conducting triage, this approach effectively speeds up the process.
Finite state machines were constructed based on the senior analysts' patterns and were used to achieve high-speed triage
with a low number of false positives.
However, limitations include a high number of false negatives as well as a dependency on high-performing security
analysts to maximize the performance of the automated system.
Extending this approach,\ \citet{lin2018data} feeds contexts into a recurrent neural network which detects matching
traces and presents these to novice analysts which in turn trains them in effective triage.

Finally, it is worth noting that a high level of automation can have adverse effects on the overall performance of
security analysts when performing triage because of the following reasons:
\begin{itemize}
    \item Understanding and conducting full-time monitoring of the automation can increase
    workload\ \citep{kaber2004effects}.
    \item The level of trust in automation can lead to over-reliance or negligence\ \citep{lee2004trust}.
\end{itemize}
Hence, it is crucial to maintain a level of human interaction when automating the steps of triage, and to prioritize
user-friendliness of integrated tools.

The limitation of all the previously proposed automations is that they do not involve NLP\@.
Triage requires understanding and interpreting content surrounding the alarm, such as logs, announcements and other
forms of natural or unstructured language, which are challenging to automate through conventional methods.
However, LLMs can be the entry point to find solutions to automate such tasks.

\subsection{General Usage of LLMs}
\label{subsec:rq1-use-of-llms}

LLMs make use of Natural Language Understanding (NLU) and Natural Language Generation (NLG).
NLU aims to comprehend meaning and intent in natural language, while NLG focuses on generating original human-like
texts.
To achieve NLU and NLG, language models make use of so-called encoders and decoders.
The purpose of encoders is to turn input texts into fixed-size vectors that act as abstract representations.
Language models then utilize decoders to transform such representations into a generated target output.
This approach works well on tasks that map input sequences to output sequences (sec2sec), such as language
translation\ \citep{sutskever2014sequence, cho2014learning}.

In 2014,\ \citet{bahdanau2014neural} introduced the concept of attention which rids the encoders of creating
fixed-length vectors.
It allows language models to focus on the most relevant parts of texts and enabling operations on much longer input
sequences.
Based on this,\ \citet{vaswani2017attention} developed the transformer architecture in 2017, setting the precedent for
modern LLMs.
Transformers are superior in quality, more parallelizable, and take less time to train.

Early well-known examples of such transformer-based models are BERT
(Bidirectional Encoder Representations from Transformers)\ \citep{devlin2018bert}, and
GPT (Generative Pre-trained Transformer)\ \citep{radford2018improving}:
\begin{itemize}
    \item BERT was specifically designed as a pre-trained model to be easily fine-tuned for a wide range of tasks such
    as answering questions and natural language inference, without the need of task-specific architecture.
    In the cybersecurity domain, BERT models have been fine-tuned to detect malicious
    software\ \citep{rahali2021malbert} and phishing emails\ \citep{lee2020catbert}, in addition to performing general
    cybersecurity tasks\ \citep{bayer2024cysecbert}.

    \item GPT is pre-trained on a large amount of unlabeled data and designed to generate coherent context-specific
    text.
    It works by generating continuations based on the input text through probabilistic guesses.
    Like BERT, it requires fine-tuning to adapt the model to specific tasks.
\end{itemize}

The disadvantage of these models is that they are relatively small and require fine-tuning to be applied to
domain-specific tasks.
Fine-tuning using domain-specific data is not only resource and time-intensive, but the resulting models have limited
applicability and can potentially include bias.
Another disadvantage is the phenomenon of catastrophic forgetting where existing models forget their original knowledge
after being trained on new data.

The introduction of much larger general models such as GPT-4\ \citep{achiam2023gpt} and Llama 3\ \citep{meta:llama3}
intends to eliminate these problems.
The broad availability and applicability of these large general models allows organizations to easily integrate them to
optimize general and specific tasks.
These models are relatively new and currently have limited research available on their use, but there are some notable
examples.

\citet{nori2023capabilities} have used GPT-4 to assess its performance on medical tests without fine-tuning.
The result shows that the model passed the tests without specialized instructions, even surpassing other models that
are fine-tuned on medical knowledge.
This shows that the significance of fine-tuning decreases when general models increase in size and capabilities.

In the cybersecurity domain, research on general models is sparse, but applications of fine-tuned LLMs still provide
valuable insights into their potential for optimizing triage.
For example,\ \citet{karlsen2024large} propose a system that uses LLMs to perform log analysis.
Where previous methods of analysis relied on rule-based or statistical approaches, LLMs are able to learn complex
patterns and relationships within log data without requiring manual feature engineering.
The study focuses on fine-tuning models such as BERT and GPT-2\ \citep{radford2019language} through self-supervised
learning where the LLMs automatically label data by identifying relations.
Larger models like GPT-4 and Llama 2\ \citep{touvron2023llama} were not used due to their high parameter counts,
leading to increased computational requirements during the fine-tuning process.

To instruct LLMs to perform tasks, prompts are used.
They consist of textual inputs that the model interprets and uses to generate contextually relevant responses.
Prompts are split into system prompts and user prompts.
System prompts act as predefined inputs that guide the model's behavior and control the context of a task.
User prompts are usually provided by end-users and describe the specific task.
They are diverse in form and content.
Creating good prompts is essential to achieve high-quality LLM outputs.
Short and simple prompts might lack sufficient context, leading to incomplete and inaccurate results.
On the other hand, excessively long and complex prompts might introduce redundant information that confuses the model.
Therefore, balancing the sizes and complexities of prompts is crucial to obtain relevant, accurate and coherent outputs.

\subsection{Using LLMs to Optimize Triage}
\label{subsec:rq1-llms-in-context}

When applying LLMs to specific tasks, it is important to keep the tasks short and simple to ensure the results are
consistent and easily testable.
Referring to the triage steps in\ \ref{subsec:rq1-steps-of-triage}, all tasks that involve natural language or
unstructured textual data have the potential to be automated using LLMs.
Since the optimizations are ideally applicable across all kinds of alarms, the following possible automations are
identified:
\begin{itemize}
    \item \textbf{Detecting if an email is an announcement:}
    This means letting the LLM process the entire email and concluding if it contains any information regarding actions
    that could trigger alarm generation.

    \item \textbf{Detecting if an announcement is related to an alarm:}
    This involves feeding both an announcement and alarm data into the LLM and determining whether a correlation
    exists, meaning the alarm was triggered by an action that was announced beforehand.

    \item \textbf{Correlating an alarm with other alarms and identifying if there are relationships:}
    Based on the alarm data, potentially related alarms are collected, after which the LLM concludes if they are in
    fact correlated.

    \item \textbf{Determining the position of an alarm in the kill chain:}
    Based on the MITRE ATT\&CK framework, alarms have a position in the kill chain.
    An LLM can use alarm data and correlated alarms to identify this position.

    \item \textbf{Determining the priority of an alarm as high, medium, low or no threat:}
    This last step is to use the answers of the previous tasks to determine if the alarm should be treated as high,
    medium, low or no priority.
\end{itemize}

In summary, incorporating LLMs into the incident response workflow by automating these steps will allow for a more
efficient triage process.